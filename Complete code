# # Descripción del proyecto:
# Para la extracción de petróleo de la empresa OilyGiant, encontraremos los mejores lugares donde abrir 200 pozos nuevos de petróleo.
# 
# Indice:
# Importación de librerías 
# Carga de datos.
# Creación de un modelo para predecir el volumen de reservas en pozos nuevos.
# Elección de los pozos petrolíferos que tienen los valores estimados más altos.
# Cálculo de riegos
# Elección de la región con el beneficio total más alto para los pozos petrolíferos seleccionados.

# # Importación de librerías:


import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix


# # Carga de datos


data0= pd.read_csv('/datasets/geo_data_0.csv')

data0.head()

data0.info()


data1= pd.read_csv('/datasets/geo_data_1.csv')

data1.head()

data1.info()


data2= pd.read_csv('/datasets/geo_data_2.csv')

data2.head()

data2.info()



data0['f0'].hist(bins=10, alpha=.4)
data1['f0'].hist(bins=10, alpha=.4)
data2['f0'].hist(bins=10, alpha=.4)


data0['f1'].hist(bins=10, alpha=.4)
data1['f1'].hist(bins=10, alpha=.4)
data2['f1'].hist(bins=10, alpha=.4)


data0['f2'].hist(bins=10, alpha=.4)
data1['f2'].hist(bins=10, alpha=.4)
data2['f2'].hist(bins=10, alpha=.4)


# Analicemos las relaciones entre las columnas en las distintas regiones 

pd.plotting.scatter_matrix(data0, figsize=(15,10))

pd.plotting.scatter_matrix(data1, figsize=(15,10))

pd.plotting.scatter_matrix(data2, figsize=(15,10))


# Vemos muy distintas relaciones entre columnas, dependiendo de la región

# # Preparación de los datos:

def split_data(data):
    
    data=data.drop(['id'], axis=1)
    
    features= data.drop(['product'], axis=1)
    
    scaler=StandardScaler()
    scaler.fit(features)
    features= scaler.transform(features)
    target=data['product']
    
    features_train, features_valid, target_train, target_valid= train_test_split(features, target, test_size=.25, random_state=(12345))

    
    return features_train, features_valid, target_train, target_valid


features_train_0, features_valid_0, target_train_0, target_valid_0 = split_data(data0)

features_train_1, features_valid_1, target_train_1, target_valid_1 = split_data(data1)

features_train_2, features_valid_2, target_train_2, target_valid_2 = split_data(data2)


# # Creación de modelo, predicción promedio, y RECM

def model_pred(features_train, features_valid, target_train, target_valid):
    
    model=LinearRegression()
    
    model.fit(features_train, target_train)
    predictions=model.predict(features_valid)
    
    average_predictions= predictions.mean()
    
    RECM= mean_squared_error(target_valid, predictions, squared=False)
    
    return model, predictions, RECM, average_predictions



model_0, predictions_0, RECM_0, average_predictions_0= model_pred(features_train_0, features_valid_0, target_train_0, target_valid_0)


model_1, predictions_1, RECM_1, average_predictions_1= model_pred(features_train_1, features_valid_1, target_train_1, target_valid_1)


model_2, predictions_2, RECM_2, average_predictions_2= model_pred(features_train_2, features_valid_2, target_train_2, target_valid_2)


print(predictions_0)
print(RECM_0)
print(average_predictions_0)


print(predictions_1)
print(RECM_1)
print(average_predictions_1)


print(predictions_2)
print(RECM_2)
print(average_predictions_2)




# Para calcular las unidades mínimas que cada pozo debería tener para evitar pérdidas:
#     Dada la inversión de 100 millones por 200 pozos petrolíferos, de media un pozo petrolífero debe producir al menos un valor de 500,000 dólares en unidades para evitar pérdidas (esto es equivalente a 111.1 unidades)

100000000/200

pozos = 200
presupuesto_total= 100000000
USD_por_unidad = 4500

presupuesto_por_pozo = presupuesto_total/pozos

unidades_mínimas = presupuesto_por_pozo/USD_por_unidad

unidades_mínimas

averages=[average_predictions_0, average_predictions_1, average_predictions_2, unidades_mínimas]



etiquetas=['average_predictions_0', 'average_predictions_1', 'average_predictions_2', 'unidades mínimas']
plt.bar(etiquetas, averages)
plt.xticks(rotation=45)
plt.title('Average predictions')


# # Top 200 predictions


def top_pred(predictions):
    top_predictions= pd.Series(predictions)

    top_predictions=top_predictions.sort_values(ascending=False)
    top_predictions=top_predictions.head(200)
    return top_predictions


top_predictions_0= top_pred(predictions_0)
top_predictions_1= top_pred(predictions_1)
top_predictions_2= top_pred(predictions_2)


top_predictions_0.mean()

top_predictions_1.mean()

top_predictions_2.mean()




top_averages=[top_predictions_0.mean(), top_predictions_1.mean(), top_predictions_2.mean(), 111.1]


etiquetas=['average_top_predictions_0', 'average_top_predictions_1', 'average_top_predictions_2', 'unidades mínimas']
plt.bar(etiquetas, top_averages)
plt.xticks(rotation=45)
plt.title('Average top predictions')


# Vamos a sacar de target_valid, los valores reales del top 200 de cada una de las regiones, según las predicciones 

def top_target(top_predictions, target_valid):
    target_valid = target_valid.reset_index(drop=True)
    top_target=target_valid.iloc[top_predictions.index]
    return top_target


top_target_0= top_target(top_predictions_0, target_valid_0)
top_target_0


top_target_1= top_target(top_predictions_1, target_valid_1)
top_target_1


top_target_2= top_target(top_predictions_2, target_valid_2)
top_target_2



# # Calculamos la ganancia según las predicciones con el top 200 de pozos 


budget=100000000
unit= 4500
def ganancias(top_predictions):
    suma= top_predictions.sum()
    ganancia= suma*unit-budget
    
    return ganancia


ganancia_predictions_0=ganancias(top_predictions_0)
ganancia_predictions_0


ganancia_predictions_1=ganancias(top_predictions_1)
ganancia_predictions_1


ganancia_predictions_2=ganancias(top_predictions_2)
ganancia_predictions_2


ganancias_predictions_bar=[ganancia_predictions_0, ganancia_predictions_1, ganancia_predictions_2]

etiquetas=['ganancia_predictions_0', 'ganancia_predictions_1', 'ganancia_predictions_2']
plt.bar(etiquetas, ganancias_predictions_bar)
plt.xticks(rotation=45)


# Vemos que la región con la ganancia más alta es la región 0



state = np.random.RandomState(12345)



def loss(values):
    
    loss_count = sum(1 for profit in values if profit < 0)

    probability_of_loss = loss_count / len(values)

    percentage_of_loss = probability_of_loss * 100
    return percentage_of_loss


# Dado que obtuvimos 0 riesgo de perdidas en todas las regiones, vamos a hacer un bootstrapping con 500 datos de las predicciones totales, para ver el risego real de las 3 regiones

def ganancias_bootstrapping_all(target, predictions):

    target=target.reset_index(drop=True)
    values = []
    for i in range(1000):
        
        subsample = pd.Series(predictions).sample(n=500, replace=True)
        subsample_top= subsample.sort_values(ascending=False).head(200)
        subtarget= target[subsample_top.index]
        ganancia= ganancias(subtarget)
        values.append(ganancia)

    values = pd.Series(values)
    mean= values.mean()
    
    lower = values.quantile(.025)
    upper = values.quantile(.975)
    intervalo_de_confianza= lower, upper
    return values, intervalo_de_confianza, mean



values_all_0, intervalo_de_confianza_all_0, mean_all_0= ganancias_bootstrapping_all(target_valid_0, predictions_0)
intervalo_de_confianza_all_0

values_all_1, intervalo_de_confianza_all_1, mean_all_1= ganancias_bootstrapping_all(target_valid_1, predictions_1)
intervalo_de_confianza_all_1

values_all_2, intervalo_de_confianza_all_2, mean_all_2= ganancias_bootstrapping_all(target_valid_2, predictions_2)
intervalo_de_confianza_all_2



mean_all_0

mean_all_1

mean_all_2


ganancias_all_bar=[mean_all_0, mean_all_1, mean_all_2]

etiquetas=['mean_all_0', 'mean_all_1', 'mean_all_2']
plt.bar(etiquetas, ganancias_all_bar)
plt.xticks(rotation=45)
plt.title('Average profit of all predictions')


loss(values_all_0)

loss(values_all_1)

loss(values_all_2)


# Conclusión: La región 1 es la única que tiene el riesgo de pérdidas menor a 2.5, y por lo tanto con el menor riesgo, además de que la ganancia promedio es la más lata, por lo que recomendamos la región 1
